# ğŸ§  Customer Churn Prediction (End-to-End ML Deployment)

[![Deploy to Azure](https://aka.ms/deploytoazurebutton)](https://portal.azure.com/#create/Microsoft.WebSite)

This project demonstrates a full MLOps workflow for predicting customer churn using logistic regression, with a production-ready API deployed to Azure and a live Gradio UI.

---

## ğŸ¤” Why This Matters (For the Common Reader)

In business, keeping your current customers is often far more valuable than gaining new ones. But how do you know which customers are about to leave?

This project tackles that challenge by using machine learning to predict customer churn â€” i.e., which customers are likely to cancel their service. With this insight, businesses can act in advance: offering better deals, addressing complaints, or making personalized contact.

What makes this system special:
- ğŸ¤– It's not just a model â€” it's fully deployed.
- âœ¨ You can interact with it through a clean API (for developers) or a simple interface (for business teams).
- âœˆï¸ It's portable, production-grade, and can be deployed to the cloud in minutes.

Think of it as your own AI assistant for customer retention.

---

## ğŸ—‚ Project Structure
```
churn-prediction-mlops-azure/
â”œâ”€â”€ data/                   # Telco churn dataset
â”œâ”€â”€ docker/                 # Dockerfile for FastAPI + Gradio
â”œâ”€â”€ notebooks/              # EDA, preprocessing notebooks
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_model.py      # Train + save pipeline
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ app.py          # FastAPI server
â”‚   â”‚   â””â”€â”€ pipeline.pkl    # Saved ML pipeline
â”‚   â””â”€â”€ ui/
â”‚       â””â”€â”€ gradio_ui.py    # Gradio app for testing
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml      # Run both FastAPI + Gradio locally
â”œâ”€â”€ README.md
```

## What This Project Demonstrates

- âœ… Data preprocessing and encoding (ColumnTransformer, NaNs, one-hot encoding)
- âœ… Logistic Regression model with pipeline encapsulation
- âœ… MLflow tracking (metrics, parameters, artifacts)
- âœ… Model saved and reused via `joblib`
- âœ… Serving predictions via FastAPI
- âœ… Live Gradio UI for manual testing
- âœ… Dockerized with one Dockerfile, multi-service Compose
- âœ… Deployed to Azure Web App for Containers / Azure Container Instances

---

## ğŸ›  Architecture Overview (C4 Model)

### 1. System Context
![System Context](out/plantuml_diagrams/C4_system_context_diagram/System_Context.png)

### 2. Container Diagram
![Container Diagram](out/plantuml_diagrams/C4_container_diagram/Container_Diagram.png)

### 3. Deployment Diagram
![Deployment Diagram](out/plantuml_diagrams/C4_deployment_diagram/Deployment_Diagram.png)

### 4. Sequence Flow
![Sequence Diagram](out/plantuml_diagrams/C4_sequence_diagram/Sequence_Diagram.png)

---
## ğŸš€ Live Demo
ğŸ‘‰ API Docs: `http://churnapi21017.westeurope.azurecontainer.io/docs`  
ğŸ‘‰ Gradio UI: `http://localhost:7860` *(or hosted Gradio link if deployed)*

---

## ğŸ›  Tech Stack
- Python 3.12
- scikit-learn, pandas, joblib
- FastAPI, Uvicorn
- Docker, Docker Compose
- Azure CLI + Azure Web App for Containers
- Gradio (UI layer)

---

## âœ¨ How to Run Locally (via Docker Compose)
```bash
git clone https://github.com/<your-username>/churn-prediction-mlops-azure.git
cd churn-prediction-mlops-azure

# Build and run both FastAPI + Gradio
docker compose up --build
```

- Visit `http://localhost:8000/docs` for API
- Visit `http://localhost:7860` for Gradio UI

---

## ğŸš¤ Deploy to Azure

1. Push Docker image to DockerHub:
```bash
docker build -t yourusername/churn-api:latest .
docker push yourusername/churn-api:latest
```

2. Deploy to Azure Web App:
```bash
az login
az group create --name churn-ml-rg --location westeurope
az appservice plan create --name churn-plan --resource-group churn-ml-rg --is-linux --sku B1
az webapp create --resource-group churn-ml-rg --plan churn-plan \
  --name churn-api-app --deployment-container-image-name yourusername/churn-api:latest
```

---

## Next Steps
- Add Streamlit dashboard (or host Gradio)
- Implement CI/CD via GitHub Actions
- Expose model version via metadata endpoint
- Auto-tag and push Docker builds via GitHub Workflow

---

## Author
**Kene Agbodike**  
_Data & AI | ML Engineering | MLOps | Cloud Deployment_