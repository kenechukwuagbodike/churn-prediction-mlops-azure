# ðŸ§  Customer Churn Prediction (End-to-End ML Deployment)
[![Deploy to Azure](https://aka.ms/deploytoazurebutton)](https://portal.azure.com/#create/Microsoft.WebSite)


This project demonstrates a full MLOps workflow for predicting customer churn using logistic regression, with a production-ready API deployed to Azure and a live Gradio UI.

---

## ðŸ—‚ Project Structure
```
churn-prediction-mlops-azure/
â”œâ”€â”€ data/                   # Telco churn dataset
â”œâ”€â”€ docker/                 # Dockerfile for FastAPI + Gradio
â”œâ”€â”€ notebooks/              # EDA, preprocessing notebooks
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_model.py      # Train + save pipeline
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ app.py          # FastAPI server
â”‚   â”‚   â””â”€â”€ pipeline.pkl    # Saved ML pipeline
â”‚   â””â”€â”€ ui/
â”‚       â””â”€â”€ gradio_ui.py    # Gradio app for testing
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml      # Run both FastAPI + Gradio locally
â”œâ”€â”€ README.md
```

## What This Project Demonstrates

- âœ… Data preprocessing and encoding (ColumnTransformer, NaNs, one-hot encoding)
- âœ… Logistic Regression model with pipeline encapsulation
- âœ… MLflow tracking (metrics, parameters, artifacts)
- âœ… Model saved and reused via `joblib`
- âœ… Serving predictions via FastAPI
- âœ… Live Gradio UI for manual testing
- âœ… Dockerized with one Dockerfile, multi-service Compose
- âœ… Deployed to Azure Web App for Containers / Azure Container Instances

---

## ðŸ›  Architecture Overview (C4 Model)

### 1. System Context
![System Context](out/plantuml_diagrams/C4_system_context_diagram/System_Context.png)

### 2. Container Diagram
![Container Diagram](out/plantuml_diagrams/C4_container_diagram/Container_Diagram.png)

### 3. Deployment Diagram
![Deployment Diagram](out/plantuml_diagrams/C4_deployment_diagram/Deployment_Diagram.png)

### 4. Sequence Flow
![Sequence Diagram](out/plantuml_diagrams/C4_sequence_diagram/Sequence_Diagram.png)

---
## ðŸš€ Live Demo
ðŸ‘‰ API Docs: `http://churnapi21017.westeurope.azurecontainer.io/docs`  
ðŸ‘‰ Gradio UI: `http://localhost:7860` *(or hosted Gradio link if deployed)*

---

## ðŸ›  Tech Stack
- Python 3.12
- scikit-learn, pandas, joblib
- FastAPI, Uvicorn
- Docker, Docker Compose
- Azure CLI + Azure Web App for Containers
- Gradio (UI layer)

---

## âœ¨ How to Run Locally (via Docker Compose)
```bash
git clone https://github.com/<your-username>/churn-prediction-mlops-azure.git
cd churn-prediction-mlops-azure

# Build and run both FastAPI + Gradio
docker compose up --build
```

- Visit `http://localhost:8000/docs` for API
- Visit `http://localhost:7860` for Gradio UI

---

## ðŸš¤ Deploy to Azure

1. Push Docker image to DockerHub:
```bash
docker build -t yourusername/churn-api:latest .
docker push yourusername/churn-api:latest
```

2. Deploy to Azure Web App:
```bash
az login
az group create --name churn-ml-rg --location westeurope
az appservice plan create --name churn-plan --resource-group churn-ml-rg --is-linux --sku B1
az webapp create --resource-group churn-ml-rg --plan churn-plan \
  --name churn-api-app --deployment-container-image-name yourusername/churn-api:latest
```

---

## Next Steps
- Add Streamlit dashboard (or host Gradio)
- Implement CI/CD via GitHub Actions
- Expose model version via metadata endpoint
- Auto-tag and push Docker builds via GitHub Workflow

---

## Author
**Kene Agbodike**  
_Data & AI | ML Engineering | MLOps | Cloud Deployment_